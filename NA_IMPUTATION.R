
#===============================================================================================
#MICE imputation
#===============================================================================================

library(mice)
library(caret)
library(VIM)

#Create a vector of column names with missing values
cols_with_na <- c("Internet.Type", "Monthly.Charge", "Age")

# Subset the data to include only the columns with missing values
data_subset <- data[, cols_with_na]

#plot number of missings:
par(mar = c(5, 5, 2, 2))

md.pattern(data_subset, rotate.names = TRUE)
aggr_plot <- aggr(data_subset, col=c('navyblue','red'), numbers=TRUE, sortVars=TRUE, labels=names(data), cex.axis=.7, gap=3, ylab=c("Histogram of missing data","Pattern"))

#A couple of notes on the parameters:

#m=5 refers to the number of imputed datasets. Five is the default value.
#meth='pmm' refers to the imputation method. In this case we are using predictive mean matching as 
#imputation method. Other imputation methods can be used, type methods(mice) for a list of the available 
#imputation methods

data_mice <- data

# Define the original vector
colnames <- colnames(data_mice)

# Initialize an empty list
lst <- list()
num_values <- c("pmm", "cart", "midastouch", "rf", "norm")
cat_values <- c("pmm", "cart", "polyreg", "lda")

# Loop over the numerical columns and categorical column
for (num_val in num_values) {
    for (cat_val in cat_values) {
      # Initialize an empty vector for the list element
      elem <- rep("", length(colnames(data)))
      
      # Assign the values to the appropriate columns
      elem[which(colnames(data)== 'Monthly.Charge')] <- num_val
      elem[which(colnames(data)== 'Age')] <- num_val
      elem[which(colnames(data)== 'Internet.Type')] <- cat_val
      
      # Add the element to the list
      lst[[length(lst) + 1]] <- elem
    }
}

methods <-lst

data_mice$Internet.Type <- as.factor(data_mice$Internet.Type)

# Initialize the misclassification rate, F1 score, and RMSE matrices
mc_mat <- matrix(0, nrow = 1, ncol = length(num_values) * length(cat_values), 
                 dimnames = list(NULL, paste(rep(num_values, each = length(cat_values)), cat_values, sep = ",")))
rmse_mat <- matrix(0, nrow = 2, ncol = length(num_values) * length(cat_values), 
                   dimnames = list(NULL, paste(rep(num_values, each = length(cat_values)), cat_values, sep = ",")))

set.seed(23122003)

# Create a loop to try different imputation methods and compute errors.
for (i in seq_along(methods)) {
  tempData <- mice(data_mice, m = 5, method = methods[[i]], maxit = 20, nblocks = 38)
  #plot is showing convergence diagnostics for each of the 5 imputed datasets that were generated by the mice() function.
  last_plot <- plot(tempData)
  
  # Save the plot as PNG file
  #png(filename = paste0("C:/Users/", colnames(rmse_mat)[i],  ".png"), width = 2000, height = 2000, res = 300)
  #print(plot(tempData))
  #dev.off()
  
  imputed_data <- complete(tempData)
  
  # Compute misclassification rate for Internet.Type
  imputed_it <- imputed_data$Internet.Type[!is.na(imputed_data$Internet.Type)]
  actual_it <- data_raw$Internet.Type[!is.na(data_raw$Internet.Type)]
  mc_mat[1, i] <- sum(imputed_it != actual_it) / length(actual_it)

  # Compute RMSE for Age and Monthly.Charge
  imputed_num <- imputed_data[, c("Age", "Monthly.Charge")]
  actual_num <- data_raw[, c("Age", "Monthly.Charge")]
  rmse_mat[1, i] <- sqrt(mean((imputed_num$Age - actual_num$Age)^2))
  rmse_mat[2, i] <- sqrt(mean((imputed_num$Monthly.Charge - actual_num$Monthly.Charge)^2))

}

#to compare with mimmi
# Apply Pythagorean theorem to each column
new_rmse_mat <- sqrt(rmse_mat[1, ]^2 + rmse_mat[2, ]^2)

new_mc_mat <- mc_mat * length(actual_it)


#===============================================================================================
#MIMMI imputation
#===============================================================================================

#install.packages("StatMatch")
library(cluster)
require(StatMatch)

Mode <- function(x) 
{
  x<-as.factor(x)
  maxV<-which.max(table(x))
  return(levels(x)[maxV])
}


#assume missings represented with NA
uncompleteVar<-function(vector){any(is.na(vector))}

MiMMi <- function(data, nclust, priork=-1)
{
  #Identify columns without missings
  colsMiss<-which(sapply(data, uncompleteVar))
  if(length(colsMiss)==0){
    print("Non missing values found")
    out<-dd
  }else{
    K<-dim(data)[2]
    colsNoMiss<-setdiff(c(1:K),as.vector(colsMiss))
    
    #cluster with complete data
    dissimMatrix <- daisy(data[,colsNoMiss], metric = "gower", stand=TRUE)
    distMatrix<-dissimMatrix^2
    
    hcdata<-hclust(distMatrix, method = "ward.D2")
    plot(hcdata)
    nk<-2
    if(priork==-1){
      nk <- nclust
      nk<-as.integer(nk)
    }else{nk<-priork}
    
    partition<-cutree(hcdata, nk)
    
    CompleteData<-data
    #nomes cal per tenir tra?a de com s'ha fet la substituci?
    newCol<-K+1
    CompleteData[,newCol]<-partition
    names(CompleteData)[newCol]<-"ClassAux"
    
    setOfClasses<-as.numeric(levels(as.factor(partition)))
    imputationTable<-data.frame(row.names=setOfClasses)
    p<-1
    
    for(k in colsMiss)
    {
      #Files amb valors utils
      rowsWithFullValues<-!is.na(CompleteData[,k])
      
      #calcular valors d'imputacio
      if(is.numeric(CompleteData[,k]))
      {
        imputingValues<-aggregate(CompleteData[rowsWithFullValues,k], by=list(partition[rowsWithFullValues]), FUN=mean)
      }else{
        imputingValues<-aggregate(CompleteData[rowsWithFullValues,k], by=list(partition[rowsWithFullValues]), FUN=Mode)
      }
      
      #Impute
      
      for(c in setOfClasses)
      {
        CompleteData[is.na(CompleteData[,k]) & partition==c,k]<-imputingValues[c,2]
      }
      
      #Imputation Table
      imputationTable[,p]<-imputingValues[,2]
      names(imputationTable)[p]<-names(data)[k]
      p<-p+1
    }
    
    rownames(imputationTable)<-paste0("c", 1:nk)
    out<-new.env()
    out$imputedData<-CompleteData
    out$imputation<-imputationTable
  }
  return(out)
}

#Only using the numerical variables and the one categorical for the imputation
nums <- unlist(lapply(data, is.numeric), use.names = TRUE)
#Set Internet Type to True
nums[17] = TRUE
#We define 3 vectors we will fill as we try different methods
#to impute NAs
cat_diffs = c()
num_diffs = c()
mimmiks = c(5,10,50,100,150,200,250,300,350)
for (nk in mimmiks){
  dimpute<-MiMMi(data[,nums], nk)
  
  #table of imputation values used
  dimpute$imputation
  
  #imputed dataset
  imputed = dimpute$imputedData[0:16]
  cluster = dimpute$imputedData[17]
  
  
  #library(arsenal)
  #summary(comparedf(data_raw[,nums],a[1:16]))
  
  categorical_vars_data_raw <- data_raw$Internet.Type
  categorical_vars_imputed <- imputed$Internet.Type
  
  # Selecting all numerical variables
  numeric_vars <- sapply(data_raw, is.numeric)
  numeric_vars_data_raw <- data_raw[, numeric_vars]
  numeric_vars <- sapply(imputed, is.numeric)
  numeric_vars_imputed <- imputed[, numeric_vars]
  
  
  # MIssclassification error
  categorical_diff <- sum(data_raw$Internet.Type != imputed$Internet.Type)
  
  # Squared error
  numeric_diff <- sum((numeric_vars_data_raw - numeric_vars_imputed)^2)
  
  # Add values to vectors
  cat_diffs = append(cat_diffs, categorical_diff)
  num_diffs = append(num_diffs, numeric_diff)
}

#Computation of the standard error
num_diffs <- sqrt(num_diffs/704)
num_diffs <- (num_diffs-min(num_diffs))/(max(num_diffs)-min(num_diffs))


# Create a first line
plot(mimmiks,final_error, type = "b", frame = FALSE, pch = 19, 
     col = "red", xlab = "#clusters", ylab = "error", ylim = c(0,1))
# Add a second line
# Add a legend to the plot
grid(nx = NULL, ny = NULL,
     lty = 2,      # Grid line type
     col = "gray", # Grid line color
     lwd = 2)      # Grid line width
legend("topright", legend=c("Numeric Diffs.", "Catgorical diffs."),
       col=c("red", "blue"), lty = 1:2, cex=0.8)
#As we can see, the number of clusters for which the error keeps reducing is quite high.
#In fact, if 450 clusters are tried, the MIMMI function provided fails. The error made on numerical numbers
#has reached it's lower limit around 150-250 clusters, but the categorical difference looks like
#would keep going down for longer.

#The difference between the lowest error in the numerical and the last one is not very significant
#but the last iteration made with 400 clusters has a remarkable lower error con the categorical value
#so this will be the chosen imputation to keep working with,

#Since it is the last one computed it is saved in:
data[nums] = dimpute$imputedData[1:16]


#===============================================================================================
#Final decision
#===============================================================================================
#Mice is way better than mimmi. We now take the best of mice:

# Define the weights for the misclassification rate and RMSE criteria
weight_mc <- 0.5
weight_rmse <- 0.25
# Compute the weighted normalized decision matrix
decision_mat <- weight_mc * m + weight_rmse * l[1,] + weight_rmse * l[2,]
mat <- decision_mat
colnames(mat)[which(mat == min(mat), arr.ind = TRUE)[2]]

#complete with the best of the decision matrix.
tempData <- mice(data_mice, m = 5, method = methods[[6]], maxit = 20, nblocks = 38)

data_mice <- complete(tempData)

path <- "C:/Users/"
save(data_mice, file = paste0(path, "base_PMAAD_SENSE_OUT_SENSE_NA.RData"))

file <- "base_PMAAD_SENSE_OUT_SENSE_NA.RData"
data <- get(load(paste0(path, file)))

#===============================================================================================
#Data verification
#===============================================================================================

#Data reload for new executions:
load("C:/Users/")
data_raw = data

data_na <- data_raw
knitr::opts_chunk$set(echo = TRUE)
library(missForest)
set.seed(42)
data_na['Internet.Type'] <- missForest::prodNA(data['Internet.Type'], noNA = 0.05)
data_na['Monthly.Charge'] <- missForest::prodNA(data['Monthly.Charge'], noNA = 0.05)
data_na['Age'] <- missForest::prodNA(data['Age'], noNA = 0.05)

load("C:/Users/")
data_final <- data

library(ggplot2)

age_list <- list(data_raw$Age, na.omit(data_na$Age), data_final$Age)
plot(density(age_list[[1]]), col = "#00AFBB", lwd = 8, main = "Comparison of Age Distributions", xlab = "Age", ylab = "Density", ylim = c(0, 0.04))
lines(density(age_list[[2]]), col = "#E7B800", lwd = 5)
lines(density(age_list[[3]]), col = "#FC4E07", lwd = 2)
legend("topright", legend = c("data_raw", "data_na", "data_final"), col = c("#00AFBB", "#E7B800", "#FC4E07"), lwd = c(2, 1.5, 1), title = "Dataset", bty = "n")


# Internet.Type Plot
cat_list <- list(data_raw$Internet.Type, data_na$Internet.Type, data_final$Internet.Type)
table_list <- lapply(cat_list, table)
barplot(do.call(rbind, table_list), beside = TRUE, col = c("#00AFBB", "#E7B800", "#FC4E07"), legend.text = c("data_raw", "data_na", "data_final"), args.legend = list(x = "topright", bty = "n"), main = "Comparison of Internet Type Distributions", xlab = "Internet Type", ylab = "Count")


#Montlhy.Charge Plot
Monthly.Charge_list <- list(data_raw$Monthly.Charge, na.omit(data_na$Monthly.Charge), data_final$Monthly.Charge)
plot(density(Monthly.Charge_list[[1]]), col = "#00AFBB", lwd = 8, main = "Comparison of Monthly.Charge Distributions", xlab = "Age", ylab = "Density", ylim = c(0, 0.04))
lines(density(Monthly.Charge_list[[2]]), col = "#E7B800", lwd = 5)
lines(density(Monthly.Charge_list[[3]]), col = "#FC4E07", lwd = 2)
legend("topright", legend = c("data_raw", "data_na", "data_final"), col = c("#00AFBB", "#E7B800", "#FC4E07"), lwd = c(2, 1.5, 1), title = "Dataset", bty = "n")

